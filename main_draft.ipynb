{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Info-284 Group exam\n",
    "Group members: Heejung Yu, Tsz Ching, Sverre-Emil and Aaron Male"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Preprocessing](#Preprocessing)\n",
    "    - [Features](#Features)\n",
    "        - [Species](#Species)\n",
    "        - [Equipment](#Equipment)\n",
    "        - [Gross Weight of Catch](#Gross-Weight-of-Catch)\n",
    "        - [Boat Information](#Boat-Information)\n",
    "        - [Location of Trip](#Location-of-Trip)\n",
    "        - [Drag Distance](#Drag-Distance)\n",
    "        - [Duration](#Duration)\n",
    "        - [Time](#Time)\n",
    "    - [Analyzation](#Analyzation)\n",
    "        - [Hovedart FAO](#Hovedart-FAO)\n",
    "        - [Lengdegruppe](#Lengdegruppe)\n",
    "        - [Redskap FAO](#Redskap-FAO)\n",
    "        - [Rundvekt](#Rundvekt)\n",
    "3. [Supervised Learning](#Supervised-Learning)\n",
    "    - [Picking the Machine Learning Models](#Picking-the-Machine-Learning-Models)\n",
    "        - [K-NN](#K-NN)\n",
    "        - [Linear Models](#Linear-Models)\n",
    "        - [Naive Bayes](#Naive-Bayes)\n",
    "        - [Decision Trees](#Decision-Trees)\n",
    "        - [Ensembles of Decision Trees](#Ensembles-of-Decision-Trees)\n",
    "        - [Neural Networks](#Neural-Networks)\n",
    "        - [Kernelized Support Vector Machines](#Kernelized-Support-Vector-Machines)\n",
    "    - [Our Choices](#Our-Choices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "After taking a quick look at the dataset and the documents that was provided with it, we figured we wanted to try to predict if an entry is a Bycatch. We believe that by being able to predict Bycatch we can find out if there are any boats that are not reporting their catches properly. We classify an entry as a Bycatch if the \"Hovedart FAO\" does not match with \"Art FAO\". We are aware this definition of a Bycatch is somewhat limited especially considering the way \"Hovedart FAO\" is chosen, but if we are to define Bycatch as species that are not the top 2-3 species we would need more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings # Got an irritating warning\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('float_format', '{:f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"H:\\Informasjonsvitenskap\\Programming\\Python\\Info-284\\Info284_Project\\Exam Task\\Dataset\\elektronisk-rapportering-ers-2018-fangstmelding-dca-simple.csv\", sep=\";\")\n",
    "\n",
    "# Dataset where the species isn't the same as the main-species\n",
    "bycatch = dataset[dataset['Art FAO'] != dataset['Hovedart FAO']]\n",
    "main_species = dataset[dataset['Art FAO'] == dataset['Hovedart FAO']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "### Picking features\n",
    "When choosing features to use from the dataset, we divided the 45 different columns into 8 different categories. \n",
    "<br>\n",
    "<br>\n",
    "The 8 categories are as follows:\n",
    "<ul>\n",
    "<li>Species</li>\n",
    "<li>Equipments used</li>\n",
    "<li>Gross weight of catch</li>\n",
    "<li>Boat information</li>\n",
    "<li>Location of trip</li>\n",
    "<li>Drag distance</li>\n",
    "<li>Duration</li>\n",
    "<li>Time</li>\n",
    "</ul>\n",
    "\n",
    "We chose to use the following features in our ML model: art, hovedart, redskap, rundvekt, lengdegruppe, hovedomr√•de.\n",
    "\n",
    "Our methodology in picking the features was first seeing how the data could be relevant for our prediction, we then plotted the data from each feature into various graphs to see the distribution and also looked at the relationship between one feature and the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Species\n",
    "\n",
    "This feature consisted mainly of \"Hovedart FAO\" and \"Art FAO\", this feature is a necessity as it is used to check if the species is classified as a Bycatch or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Equipments\n",
    "\n",
    "How can we measure the usefulness of equipments when predicting Bycatch? We checked the distribution of equipments in the original dataset and compared it with the Bycatch dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A count of instances of equipment used for every Bycatch. \n",
    "count_of_equipment_used_for_only_Bycatch = bycatch.groupby([\"Redskap FAO\"])[\"Redskap FAO\"].count()\n",
    "count_of_equipment_used_for_only_Bycatch = count_of_equipment_used_for_only_Bycatch.sort_values(ascending=False)\n",
    "count_of_equipment_used_for_only_Bycatch.plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A count of instances of equipment used for every species. \n",
    "count_of_equipment_used_for_original_dataset = dataset.groupby([\"Redskap FAO\"])[\"Redskap FAO\"].count()\n",
    "count_of_equipment_used_for_original_dataset = count_of_equipment_used_for_original_dataset.sort_values(ascending=False)\n",
    "count_of_equipment_used_for_original_dataset.plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although there were a few difference in the distribution, the Bycatch dataset had a more noticeable sections whereas the original dataset had a steady decline. We didn't find there were too much of a difference between the two, and were unsure if it was relevant. So we tried another approach, we checked the correlation between the most common Bycatch species and their equipment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the most common bycatch, defined by Bycatch species with highest roundweight. \n",
    "count_of_Bycatches_for_every_main_species = bycatch.groupby([\"Art FAO\"])[\"Rundvekt\"].sum()\n",
    "\n",
    "# Top 5 species \n",
    "top_5_common_bycatch = (count_of_Bycatches_for_every_main_species.sort_values(ascending=False))[:5]\n",
    "top_5_common_bycatch = list(top_5_common_bycatch.index)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 12)) \n",
    "\n",
    "positions = np.arange(len(top_5_common_bycatch))*3  \n",
    "width = 0.5\n",
    "\n",
    "# Finding the most common equipment used for catching each of these species\n",
    "for i, species in enumerate(top_5_common_bycatch):\n",
    "    species_only_dataset = bycatch[bycatch[\"Art FAO\"] == species]\n",
    "    count_of_equipment_used = species_only_dataset.groupby(\"Redskap FAO\")[\"Redskap FAO\"].count()\n",
    "    top_equipment_for_species = count_of_equipment_used.sort_values(ascending=False).head(5) \n",
    "    \n",
    "    for j, equipment in enumerate(top_equipment_for_species.index):\n",
    "        ax.bar(positions[i] + j*width, top_equipment_for_species[equipment], width, label=f'{species} - {equipment}')\n",
    "\n",
    "ax.set_xlabel('Species and Equipment')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Top Bycatch Species and Their Most Common Equipment')\n",
    "\n",
    "ax.set_xticks(positions + width)\n",
    "ax.set_xticklabels(top_5_common_bycatch)\n",
    "\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the distribution of most common equipment used for each species varies a lot, although the top equipments for the species are the same, the rest of the equipments varies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gross weight of catch \n",
    "\n",
    "This one is relevant because of the way main species is calculated; \"Main species caught, reported using the FAO species code. Main species is chosen using highest estimated weight in round kilograms.\" (datadokumentasjon-ers-rapport-varnivaa-5-140121, p.11) This means that the main species caught on average will be higher than if it were a Bycatch.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boat information\n",
    "\n",
    "We chose to use Length group because the data in this feature is already categorized which makes it easier to process and use. We believe that the boat size is relevant when we use it together with equipments as we believe bigger boats use trawl equipments more often. We checked the distribution of equipments for every boat size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "every_lengthgroup = [\"28 m og over\", \"21-27,99 m\", \"15-20,99 m\"]\n",
    "\n",
    "for length_group in every_lengthgroup:\n",
    "        lengdegruppe_dataset = dataset[dataset[\"Lengdegruppe\"] == length_group]\n",
    "        lengdegruppe_equipmentcount = lengdegruppe_dataset.groupby([lengdegruppe_dataset[\"Redskap FAO\"]])[\"Redskap FAO\"].count()\n",
    "        lengdegruppe_equipmentcount.sort_values(ascending=False, inplace=True)\n",
    "        print(f\"Top 3 common equipment for boats in category: {length_group}\\n{lengdegruppe_equipmentcount.head(3)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the distribution of equipments used in bigger boats is much more skewed towards trawls than the distribution in smaller boat. Therefore we believe that bigger boats are more likely to result in Bycatch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Location of trip\n",
    "\n",
    "To check if the area is relevant we chose to look at a Bycatch and main species dataset for torsk (Because it is the most common species). We compared the areas where they were caught as a Bycatch and where they were caught as the main species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torsk_only = dataset[dataset['Art FAO'] == \"Torsk\"]\n",
    "torsk_only_Bycatch = torsk_only[torsk_only['Hovedart FAO'] != \"Torsk\"]\n",
    "torsk_only_main = torsk_only[torsk_only['Hovedart FAO'] == \"Torsk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Count the occurrences of each unique value in 'Hovedomr√•de start', sort, and select top 10\n",
    "top_10_areas_bycatch_start = torsk_only_Bycatch['Hovedomr√•de start'].value_counts().head(10)\n",
    "\n",
    "# Plot the top 10 areas\n",
    "top_10_areas_bycatch_start.plot(kind='pie', figsize=(12, 10), fontsize=10, autopct='%1.1f%%', startangle=140)\n",
    "\n",
    "plt.title('Top 10 Torsk Bycatch Main Start Areas', fontsize=12)\n",
    "plt.ylabel('')\n",
    "plt.legend(title='Main Start Areas', loc='upper right', bbox_to_anchor=(0, 1))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Count the occurrences of each unique value in 'Hovedomr√•de start', sort, and select top 10\n",
    "top_10_areas = torsk_only_main['Hovedomr√•de start'].value_counts().head(10)\n",
    "\n",
    "# Plot the top 10 areas\n",
    "top_10_areas.plot(kind='pie', figsize=(12, 10), fontsize=10, autopct='%1.1f%%', startangle=140)\n",
    "\n",
    "plt.title('Top 10 Torsk Non-Bycatch Main Start Areas', fontsize=12)\n",
    "plt.ylabel('')\n",
    "plt.legend(title='Main Start Area', loc='upper right', bbox_to_anchor=(0, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is interestingly a big difference where the fish is caught when we compare Bycatch with main species. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drag distance\n",
    "\n",
    "To check if drag distance is relevant when predicting Bycatch we just took a quick look and compared values. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Duration for original dataset:\\n\", dataset[\"Trekkavstand\"].describe())\n",
    "print(\"\\n\")\n",
    "print(\"Duration for bycatch:\\n\",bycatch[\"Trekkavstand\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't look like there is anything special here, maybe we can check drag distance for torsk when a specific equipment is used? We used the most common equipment for catching torsk: Bunntr√•l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torsk_only_dragdistance = dataset[dataset[\"Art FAO\"] == \"Torsk\"]\n",
    "# Removing an outlier so its easier to read the graph\n",
    "torsk_only_dragdistance = torsk_only_dragdistance[torsk_only_dragdistance[\"Trekkavstand\"] < 200000]\n",
    "\n",
    "torsk_as_Bycatch_dragdistance = torsk_only_dragdistance[torsk_only_dragdistance[\"Hovedart FAO\"] != \"Torsk\"]\n",
    "torsk_as_Bycatch_dragdistance = torsk_as_Bycatch_dragdistance[torsk_as_Bycatch_dragdistance[\"Redskap FAO\"] == \"Bunntr√•l, otter\"]\n",
    "\n",
    "\n",
    "torsk_as_main_dragdistance = torsk_only_dragdistance[torsk_only_dragdistance[\"Hovedart FAO\"] == \"Torsk\"]\n",
    "torsk_as_main_dragdistance = torsk_as_main_dragdistance[torsk_as_main_dragdistance[\"Redskap FAO\"] == \"Bunntr√•l, otter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Scatter plot for bycatch\n",
    "plt.scatter(torsk_as_Bycatch_dragdistance[\"Rundvekt\"], torsk_as_Bycatch_dragdistance[\"Trekkavstand\"], color='blue', alpha=0.5, label='Torsk as Bycatch')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel(\"Gross Weight (kg)\", fontsize=14)\n",
    "plt.ylabel(\"Distance Traveled (km)\", fontsize=14)\n",
    "plt.title(\"Amount of Torsk Caught per Distance Traveled\", fontsize=16)\n",
    "\n",
    "# Adding a legend to distinguish between the two datasets\n",
    "plt.legend(title=\"Catch Type\", title_fontsize='13', fontsize='12')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Scatter plot for main catch\n",
    "plt.scatter(torsk_as_main_dragdistance[\"Rundvekt\"], torsk_as_main_dragdistance[\"Trekkavstand\"], color='red', alpha=0.5, label='Torsk as Main Catch')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel(\"Gross Weight (kg)\", fontsize=14)\n",
    "plt.ylabel(\"Distance Traveled (km)\", fontsize=14)\n",
    "plt.title(\"Amount of Torsk Caught per Distance Traveled\", fontsize=16)\n",
    "\n",
    "# Adding a legend to distinguish between the two datasets\n",
    "plt.legend(title=\"Catch Type\", title_fontsize='13', fontsize='12')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amount of entries from 40 000 to 75 000 in Bycatch\n",
    "filtered_dragdistance = torsk_as_Bycatch_dragdistance[(torsk_as_Bycatch_dragdistance[\"Trekkavstand\"] > 40000) & (torsk_as_Bycatch_dragdistance[\"Trekkavstand\"] < 75000)]\n",
    "\n",
    "total_instances = filtered_dragdistance.shape[0]\n",
    "\n",
    "print(total_instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that drag distance makes very little difference, most of the dots in the scatterplot is concentrated around 50-60k. while there are a bit fewer dots in the main species graph around 60k it is only 800 entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duration\n",
    "\n",
    "To check if duration is relevant when predicting Bycatch we just took a quick look and compared values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Duration for original dataset:\\n\", dataset[\"Varighet\"].describe())\n",
    "print(\"\\n\")\n",
    "print(\"Duration for bycatch:\\n\", bycatch[\"Varighet\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the 25, 50 and 75 percentile are more or less the same, we believe this doesn't really help us predict Bycatch anyways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time\n",
    "\n",
    "To see the relevance of time for our ml model, we can compare the start times of each fishing trip for torsk where the equipment used is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torsk_only_Bycatch_bunntr√•l = torsk_only_Bycatch[torsk_only_Bycatch[\"Redskap FAO\"] == \"Bunntr√•l, otter\"]\n",
    "torsk_only_main_bunntr√•l = torsk_only_main[torsk_only_main[\"Redskap FAO\"] == \"Bunntr√•l, otter\"]\n",
    "\n",
    "# Convert columns to datetime format to extract the hour\n",
    "torsk_only_Bycatch_bunntr√•l['Startklokkeslett'] = pd.to_datetime(torsk_only_Bycatch_bunntr√•l['Startklokkeslett'], format='%H:%M')\n",
    "torsk_only_main_bunntr√•l['Startklokkeslett'] = pd.to_datetime(torsk_only_main_bunntr√•l['Startklokkeslett'], format='%H:%M')\n",
    "\n",
    "# Extract the hour from the start time in both main and Bycatch dataframe\n",
    "torsk_only_Bycatch_bunntr√•l['Startklokkeslett_time'] = torsk_only_Bycatch_bunntr√•l['Startklokkeslett'].dt.hour\n",
    "torsk_only_main_bunntr√•l['Startklokkeslett_time'] = torsk_only_main_bunntr√•l['Startklokkeslett'].dt.hour\n",
    "\n",
    "# counting hours\n",
    "hourly_distribution_start = torsk_only_Bycatch_bunntr√•l['Startklokkeslett_time'].value_counts().sort_index()\n",
    "hourly_distribution_start2 = torsk_only_main_bunntr√•l['Startklokkeslett_time'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose to use a pie-chart because it visualizes the data better when we want to see percentage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "hourly_distribution_start.plot(kind='pie', autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Hourly Distribution of Torsk Bycatch Start Times')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "hourly_distribution_start2.plot(kind='pie', autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Hourly Distribution of Torsk Bycatch Start Times')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the start times for Bycatch and main species are basically the same, this makes us believe that it doesn't really matter when the fishing is done as it doesn't impact the statistics for Bycatch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzation\n",
    "The primary objective of this analysis is to explore findings related to outliers within each chosen features of our dataset. By examining these outliers, we aim to understand their impact on the dataset and determine appropriate strategies for handling them. This process involves identifying outliers, assessing their significance, and deciding on actions such as keeping, modifying, or removing these outliers.\n",
    "#### Hovedart FAO\n",
    "Considering that \"Hovedart FAO\" will be the feature we use to identify if it is a Bycatch the only thing we have to consider are NaN values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[\"Hovedart FAO\"].isna().sum())\n",
    "print(dataset[\"Art FAO\"].isna().sum())\n",
    "\n",
    "# Drop all rows where Hovedart FAO and Art FAO is NaN\n",
    "dataset = dataset.dropna(subset=[\"Hovedart FAO\", \"Art FAO\"])\n",
    "\n",
    "print(dataset[\"Hovedart FAO\"].isna().sum())\n",
    "print(dataset[\"Art FAO\"].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering that this feature will be a vital part of our ml model we will be dropping all NaN values in this feature, and also considering there are only 5000 entries which is missing the species it shouldn't impact our model that much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lengdegruppe\n",
    "Considering this feature is already categorized outliers aren't an issue here, we believe its only relevant to look at NaN values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[\"Lengdegruppe\"].isna().sum())\n",
    "\n",
    "lengdegruppe_is_NaN = dataset[(dataset[\"Lengdegruppe\"].isna())]\n",
    "\n",
    "pd.DataFrame(lengdegruppe_is_NaN.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance we were planning on dropping these values, however when we actually look at the values here we can see that most catches without a specified boat length is when Stortare is caught. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_fao_counts_lengdegruppe = lengdegruppe_is_NaN['Art FAO'].value_counts()\n",
    "\n",
    "# Printing the counts for each unique value in 'Art FAO'\n",
    "print(art_fao_counts_lengdegruppe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like rather than dropping NaN values we will be converting them into a special group, this is because all NaN values are catching Stortare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Lengdegruppe'] = dataset['Lengdegruppe'].fillna('Stortare b√•ter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redskap FAO\n",
    "Looking at NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[\"Redskap FAO\"].isna().sum())\n",
    "redskap_FAO_is_NaN = dataset[dataset[\"Redskap FAO\"].isna()]\n",
    "pd.DataFrame(redskap_FAO_is_NaN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering there are only 200 NaN values the easiest solution will be dropping them, although they have aren't missing any values other than Redskap FAO we feel that the amount of work that would be needed to impute or replace the missing values will be unnoticeable in the ml models accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna(subset=[\"Redskap FAO\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rundvekt\n",
    "When looking at outliers we can assume that since different species most likely have a different average gross weight we should be looking for outliers for each individual species. We chose to use box plots to visualize these because they show outliers well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_grossweight = dataset.groupby(\"Art FAO\")[\"Rundvekt\"].apply(list)\n",
    "\n",
    "# Define the species of interest\n",
    "species_of_interest = [\"Torsk\", \"Hyse\", \"Sei\"]\n",
    "\n",
    "# Filter the aggregated data to include only the species of interest\n",
    "filtered_species_grossweight = {species: weights for species, weights in species_grossweight.items() if species in species_of_interest}\n",
    "\n",
    "# Iterate over the filtered Series using .items() for species and their corresponding gross weights\n",
    "for species, grossweights in filtered_species_grossweight.items():\n",
    "    plt.figure(figsize=(10, 6))  # Create a new figure for each species\n",
    "    \n",
    "    # Create a boxplot for the species\n",
    "    plt.boxplot(grossweights)\n",
    "    plt.title(f'Boxplot of Rundvekt for {species}')\n",
    "    plt.ylabel('Rundvekt')\n",
    "    plt.xticks([1], [species])  # Set the x-tick to the name of the current species\n",
    "    \n",
    "    plt.show()  # Show the plot for the current species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like there are many outliers for each species, we believe it will be difficult to outright remove outliers since there are 122 different species and there are probably some species with few outliers while others have a lot. According to \"Introduction to Machine Learning with Python: A Guide for Data Scientists\" by Andreas C. M√ºller and Sarah Guido (p.133), employing a RobustScaler offers a strategic solution to this issue. The RobustScaler effectively transforms the data by ignoring points that significantly deviate from the rest, making it particularly suitable for our dataset where outliers are prevalent but their outright removal is impractical.\"\n",
    "\n",
    "Checking for NaN values in Gross weight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[\"Rundvekt\"].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised learning\n",
    "In \"Introduction to Machine Learning with Python\", the book discusses seven different machine learning models: k-Nearest Neighbors (k-NN), linear models, Naive Bayes, decision trees, ensembles of decision trees, neural networks, and kernelized support vector machines (SVMs). \n",
    "\n",
    "### Picking the Machine learning models \n",
    "Considering we have 6 features, where 5 of them are categorical and 1 is continuous data, we will have to keep this distribution in mind when picking out models. \n",
    "\n",
    "#### K-NN\n",
    "\n",
    "#### Linear models\n",
    "\n",
    "#### Naive Bayes\n",
    "\n",
    "#### Decision trees\n",
    "\n",
    "#### Ensembles of decision trees\n",
    "\n",
    "#### Neural networks\n",
    "\n",
    "#### Kernelized support vector machines\n",
    "\n",
    "### Our choices "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
